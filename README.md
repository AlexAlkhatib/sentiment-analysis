# ğŸ¦ Twitter Sentiment Analysis

**DÃ©tection, nettoyage et classification automatique de tweets (positif / neutre / nÃ©gatif)**
**Techniques : NLP, TextBlob/TF-IDF, Random Forest, visualisations**


## ğŸ“Œ **Description du Projet**

Ce projet vise Ã  analyser des tweets pour dÃ©terminer leur **sentiment** :
â¡ï¸ **Positif**
â¡ï¸ **Neutre**
â¡ï¸ **NÃ©gatif**

Le pipeline complet inclut :

âœ”ï¸ Nettoyage et prÃ©paration des tweets
âœ”ï¸ PrÃ©traitement linguistique (stopwords, lemmatisation, racinisationâ€¦)
âœ”ï¸ Vectorisation TF-IDF
âœ”ï¸ Construction d'un pipeline sklearn
âœ”ï¸ Classification via **RandomForestClassifier**
âœ”ï¸ Ã‰valuation (accuracy, f1-scoreâ€¦)
âœ”ï¸ Visualisations (wordcloud, histogrammes, distributions)

Dataset utilisÃ© :
ğŸ‘‰ **Tweets Airlines Sentiment Dataset** (14 640 tweets)


## ğŸ“‚ **Structure des DonnÃ©es**

Colonnes importantes :

| Colonne           | Description                                   |
| ----------------- | --------------------------------------------- |
| text              | Contenu du tweet                              |
| airline_sentiment | Label initial (positive / neutral / negative) |
| airline           | Compagnie aÃ©rienne mentionnÃ©e                 |
| retweet_count     | Nombre de retweets                            |
| negativereason    | Cause du sentiment nÃ©gatif (si applicable)    |
| user_timezone     | Fuseau horaire de lâ€™utilisateur               |

Target utilisÃ©e :

```
positive â†’ 2  
neutral â†’ 1  
negative â†’ 0
```


## ğŸ› ï¸ **PrÃ©traitement des DonnÃ©es**

### ğŸ”¹ 1. Nettoyage du texte

Chaque tweet subit :

* Mise en minuscule
* Suppression des mentions *@username*
* Suppression des URLs
* Suppression des hashtags
* Suppression des nombres
* Suppression des stopwords
* Lemmatisation
* Racinisation (stemming)
* Nettoyage des caractÃ¨res spÃ©ciaux

Fonction utilisÃ©e :

```python
def clean_text(text):
    res = text.lower()
    res = re.sub("@\S+", "", res)
    res = re.sub("http[^\s]+|www\S+", "", res)
    res = res.replace("#", "")
    res = re.sub("\d+", "", res)
    res = [w for w in res.split() if w not in stopwords.words("english")]
    
    lemmatizer = WordNetLemmatizer()
    res = [lemmatizer.lemmatize(w) for w in res]

    stemmer = LancasterStemmer()
    res = [stemmer.stem(w) for w in res]

    res = " ".join(res)
    return res
```


### ğŸ”¹ 2. PrÃ©traitement des variables numÃ©riques & catÃ©gorielles

âœ”ï¸ **NumÃ©riques** â†’ Imputation KNN + Normalisation
âœ”ï¸ **CatÃ©gorielles** â†’ OneHotEncoding
âœ”ï¸ **Texte** â†’ Pipeline TF-IDF

Pipeline :

```python
preprocessor = ColumnTransformer(
    transformers=[
        ("num", num_pipeline, num_variables),
        ("cat", cat_pipeline, cat_variables),
        ("text", text_pipeline, "text")
    ],
    remainder="passthrough",
    verbose=True
)
```


## ğŸ¤– **ModÃ¨le de Classification**

ModÃ¨le principal :
â¡ï¸ **Random Forest Classifier**

```python
pipeline = Pipeline([
    ("preprocessor", preprocessor),
    ("rf", RandomForestClassifier())
])
pipeline.fit(X_train, y_train)
```

### ğŸ“Š **Performances obtenues**

```
Accuracy : ~87%
F1-score nÃ©gatif : 0.95
F1-score neutre : 0.76
F1-score positif : 0.67
```


## ğŸ§ª **PrÃ©diction sur phrases personnalisÃ©es**

```python
sentences = [
    "Just touched down after an amazing flight!",
    "Flight delayed again? You're killing my schedule here.",
    "Neutral flight experience today."
]

df_sentences = pd.DataFrame({"text": sentences})
pipeline.predict(df_sentences)
```


## ğŸ“ˆ Visualisations Incluses

* Wordcloud des tweets positifs / nÃ©gatifs
* Barplot des sentiments
* Distribution des mots
* Importance des features (TF-IDF + metadata)

Exemple dâ€™importance des features :

| Feature                   | Importance |
| ------------------------- | ---------- |
| negativereason_confidence | 0.176      |
| text__thank               | 0.045      |
| text__flight              | 0.009      |
| airline                   | 0.008      |


## ğŸš€ **Technologies UtilisÃ©es**

* **Python**
* pandas
* numpy
* scikit-learn
* nltk
* TF-IDF Vectorizer
* matplotlib / seaborn
* RandomForestClassifier


## â–¶ï¸ **Lancer le Projet**

### 1. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 2. Lancer lâ€™analyse

```bash
python sentiment_analysis.py
```

### 3. Tester une prÃ©diction

```bash
python predict.py --text "The flight was amazing!"
```


## âœ¨ AmÃ©liorations Futures

* Fine-tuning avec **Naive Bayes**, **SVM**, **Transformers**
* Lemmatisation amÃ©liorÃ©e via spacy
* Dashboard Streamlit
* Analyse temporelle des tweets
* DÃ©tection d'ironie et sarcasme


## ğŸ‘¤ Auteur

**Alex Alkhatib**
Projet NLP â€” Classification de Tweets par Sentiment


## ğŸ“„ Licence
MIT License
Copyright (c) 2025 Alex Alkhatib
